{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My name is Jerome Blanchet, my educational background is in pure mathematics and economics.\\\n",
    "I am senior analyst at CMHC national office. This is my personal data science site at Github.\\ \n",
    "This is actually my first notebook ever and I am very excited about it. \n",
    "\n",
    "I am interested about Numerai, a Silicon Valley firm focusing about predicting the Stock Market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "import seaborn as sns\n",
    "from pandas import DataFrame\n",
    "import time\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, VotingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import save_model, load_model\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "DATA = pd.read_csv(\"C:/Users/jeblanch/Documents/numerai_training_data.csv\")\n",
    "\n",
    "trainx = DATA.columns[:-1]\n",
    "trainy = DATA.columns[-1]\n",
    "\n",
    "DATA[trainx] = DATA[trainx].astype(np.int32)\n",
    "DATA[trainy] = DATA[trainy].astype(np.int32)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(400, input_dim=DATA[trainx].shape[1]))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(300))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"rmsprop\")\n",
    "\n",
    "fit = model.fit(DATA[trainx].values, DATA[trainy], validation_split=0.2, batch_size=5000, nb_epoch=150, verbose=0)\n",
    "\n",
    "hist = fit.history\n",
    "\n",
    "models_history = {}\n",
    "models_history['mlp_v1'] = hist\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(400, input_dim=DATA[trainx].shape[1]))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(300))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"rmsprop\")\n",
    "\n",
    "fit1 = model.fit(DATA[trainx].values, DATA[trainy], validation_split=0.2, batch_size=5000, nb_epoch=150, verbose=0)\n",
    "\n",
    "hist1 = fit1.history\n",
    "\n",
    "models_history['mlp_v2'] = hist1\n",
    "\n",
    "def plot_mlp_loss(history, title):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "    fig.set_size_inches(16,5)\n",
    "\n",
    "    ax1.set_title('{} 150 epochs'.format(title))\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_ylim([0.68,0.74])\n",
    "    ax1.grid(True)\n",
    "    ax1.plot(history['loss'], label='Training Loss')\n",
    "    ax1.plot(history['val_loss'], label='Validation Loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.set_title('{} last 50 epochs'.format(title))\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax1.set_ylim([0.68,0.74])\n",
    "    ax2.grid(True)\n",
    "    ax2.set_xticklabels(range(450,500,5))\n",
    "    ax2.plot(history['loss'][450:500], label='Training Loss')\n",
    "    ax2.plot(history['val_loss'][450:500], label='Validation Loss')\n",
    "    ax2.legend()\n",
    "    \n",
    "plot_mlp_loss(models_history['mlp_v1'], 'mlp_v1')  \n",
    "plot_mlp_loss(models_history['mlp_v2'], 'mlp_v2')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
